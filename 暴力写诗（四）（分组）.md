### 暴力写诗（四）（聚类：社区发现）

​	上回说到，利用比较频率的方法，我们将一句五言诗每一句话的后面三个字，符合语义逻辑的分成一个单字词和一个双字词。然后将双字词和单字词进行组合，写出了大致上像人话的句子。

​	接下来，今天我们要开始探讨押韵的问题。

​	对于一首五言诗：

```
1. 床前明月光，
2. 疑是地上霜。
3. 举头望明月，
4. 低头思故乡。
```

​	关于押韵我们知道下面的**事实**：

1. 一首诗的每一小节中，第二句和第四句押韵（ 后来我发现了，也有许多不押韵的奇葩 -_-）
2. 第二句、第四句分别与第三句，都**不**押韵（这一点，比较靠谱）
3. 第一句可能押韵，也可能不押韵



​	那么我们怎样才能使我们写的诗的第二句和第四句押韵呢？

​	回答是，我们要能够判断**任意给定的两个字是不是押韵**。

​	要回答这个问题，当然我们有现成的答案，例如搜索《中华新韵》。但是，不要忘了，我们是**暴力**写诗，我们要从这十万首诗中，**洞察**出汉字押韵的规律来。

​	因此，关于押韵这件事，我们所面临的局面是这样的：

1. 我们知道一些字因为**某种原因**是相互押韵（属于一组）的，是什么原因我们不知道
2. 一共有**多少种**韵（组）我们也不知道
3. 我们手上有 100 多万句已知位置（是诗中的第 N 句）的话，根据一句话的位置，我们可以知道具体的两个字的关系是：
    - **可能**押韵（同一组），如果它们刚好是第二句、第四句的最后一个字，例如”霜“和”乡“
    - **很可能**不押韵（不同组），如果它们其中一个是第二、四句的最后一个字（例如”霜“、”乡“），而另外一个是第三句的最后一个字（例如”月“）

    - 不清楚，如果它们其中一个是第一句的最后一个字

​	所以，要实现押韵的目的，问题实际上等价于，要实现以下三个要求：

1. 把可能出现在一、二、四句最后一个位置的**所有的字**，分成若干的**组**（韵）

2. 每一组内的字都相互押韵

3. 特别的，一个字可以属于不同的组（坑爹的多音字！）

​	

​	现在开始想破脑袋啦！

​	如果我们将每一个可能的字看做一个无向图的**节点**。那么利用我们手头上十来万首诗，就可以根据第二、三、四句的最后一个字的押韵关系，来标记为它们的**边**，它们之间的押韵关系，就是这些边的权。

​	例如我们考察三首诗：

```
（一）
白日依山尽
黄河入海流
欲穷千里目
更上一层楼
（二）
床前明月光
疑是地上霜
举头望明月
低头思故乡
（三）
渡远荆门外
来从楚国游
山随平野尽
江入大荒流

月下飞天镜
云生结海楼
仍怜故乡水
万里送行舟
```

​	通过诗（一），我们可以得到这样的一个图：

![1574317594770](C:\Users\nanfei_liu\AppData\Roaming\Typora\typora-user-images\1574317594770.png)

​	刚才说过，每一句最后一个字，我们看作一个图的节点。而它们之间（押韵）的关系，我们记为边的权。如果押韵（第二句和第四句的字之间），我们将它们的边的权 +3。而不押韵的关系，我们将它们之间的边的权 -5。第一句最后一个字“尽”与其它三个字没有直接关系，我们把它放到一边，不理睬。

​	同样的，我们把诗（二）也放进来考察，可以得到下面的图：

![1574317803146](C:\Users\nanfei_liu\AppData\Roaming\Typora\typora-user-images\1574317803146.png)

​	诗（二）的四个字与诗一不重复，因此，简单的追加即可。

​	下面如果把诗（三）也放进来考察呢？结果就变成了这样：

![1574317871761](C:\Users\nanfei_liu\AppData\Roaming\Typora\typora-user-images\1574317871761.png)

​	诗（三）中新出现“镜”“外”因为是第一句，单独放一边。而第三句的“尽”“水”分别与“游”“流”和“楼”“舟”之间建立了不押韵的关系（权 -5）。

​	聪明的你到这里，也许已经想到了：如果我们把所有的句子都考察一遍，就能得到出现在所有句子末尾的字之间相互的押韵关系。

​	如果我们将不押韵的（例如负数的）权的边去除，那么押韵（分组）的问题，就变成了求这个图的所有**极大连通子图（又称连通分量）**的问题。

​	这实在是太棒啦！

​	为了接下来的工作，这里超级隆重的向大家吐血推荐一款软件 Gephi。用这个软件，可以极为方便的对图进行可视化的分析。例如下图就是一个例子。

​	![1574318269604](D:\myfiles\poem\picture\4-4.png)

（大批量数据的简单分组问题，我们希望可以转化为求一个图的所有极大连通子图的问题）

​	

​	那么我们就开始干，这里面有几个小细节要补充说明一下：

1. 我们的样本数据中不押韵的诗实在是太多，不是一般的多！而反观第三句，很少有弄错会跟二四句押韵的。因此，出现在二四句末尾两个字相互之间押韵的**正确性（概率）**，要比二四句末尾的字与第三句末尾的字不押韵的**正确性（概率）**要低很多

2. 对于那些极低频次的字，我们按照老办法，舍弃。经过多次尝试，只选择第二句和第四句末尾出现的高频字开始分析，效果要好得多
3. 多音字给我们带来了很大的麻烦

代码如下：

```python
import sys
import json

'''
统计诗歌样本的押韵情况，尝试进行聚类分析
'''
with open('pos_freq.json', 'r', encoding='utf-8-sig') as f:
    data = json.loads(f.read())

word_9 = data['9']
word_19 = data['19']

word_9_list = sorted(word_9.items(), key=lambda x:x[1], reverse=True)
word_19_list = sorted(word_19.items(), key=lambda x:x[1], reverse=True)
# 取出第 10 个字和第 20 个字的前 1000 个高频字，用于成诗
word_9_list = [_[0] for _ in word_9_list[:1000]]
word_19_list =[_[0] for _ in word_19_list[:1000]]

word_set_9 = set(word_9_list)
word_set_19 = set(word_19_list)
# 合并去重
word_set = word_set_9 | word_set_19

# 开始分析
with open('five.json', 'r', encoding='utf-8-sig') as f:
    data = json.loads(f.read())

# 以下为图论操作
graph = {}
nodes = set()

# 边的格式是：{“甲,乙”:甲与乙押韵的可能性}
def add_rhyme_edge(a, b, G):
'''
添加一条押韵的边
'''
    if a < b:
        a, b = b, a
    
    _key = a + ',' + b
    if _key in G.keys():
        # 此处的 2 代表出现一次所增加的押韵的可能性权重，这是一个重要的参数
        G[_key] += 2
    else:
        G[_key] = 2


def add_not_rhyme_edge(a, b, G):
'''
添加一条不押韵的边
'''
    if a < b:
        a, b = b, a

    _key = a + ',' + b
    if _key in G.keys():
        # 此处的 -10 代表出现一次所增加的不押韵的可能性权重，这也是一个重要的参数
        G[_key] -= 10
    else:
        G[_key] = -10


for _ in data:
    poem = _['paragraphs']
    if len(poem) <= 1:
        continue
    
    i = 0
    # 一次取一小节，两句，一共 4 小句诗
    two_sentence = poem[i : i+2]
    while len(two_sentence)>1:
        # 不是五言的直接不考察
        if len(two_sentence[0]) == 12 and len(two_sentence[1]) == 12:
            #word_1 = two_sentence[0][4]
            # 第 10 个字
            word_2 = two_sentence[0][10]
            # 第 15 个字
            word_3 = two_sentence[1][4]
            # 第 20 个字
            word_4 = two_sentence[1][10]
            # 仅考察高频字集合中的字
            if word_2 in word_set and word_4 in word_set:
                add_not_rhyme_edge(word_3, word_2, graph)
                add_not_rhyme_edge(word_3, word_4, graph)
                add_rhyme_edge(word_2, word_4, graph)
        i += 2
        two_sentence = poem[i : i+2]

keys = list(graph.keys())
for _ in keys:
    # 如果押韵可能性小于 7 （经过多次实验，押韵的界限设为这个值比较合理）就去掉这条边
    if graph[_] < 7:
        del graph[_]
    else:
        nodes.add(_[0])
        nodes.add(_[-1])

nodes_data = list(nodes)
# 组合成全字符串用于快速统计出现的次数
graph_key_str = ''.join(list(graph.keys()))

for _node in nodes:
	# 如果出现的字数只有两次，仍然不考察
    if graph_key_str.count(_node) <= 2:
        del_list = []
        for _key in graph.keys():
            if _node in _key:
                del_list.append(_key)

        for _key in del_list:
            #print('deleted ', _key)
            del graph[_key]

nodes_new = set()
keys = list(graph.keys())
for _ in keys:
    nodes_new.add(_[0])
    nodes_new.add(_[-1])

nodes_data = list(nodes_new)
# 写入 csv 文件，用于 Gephi 软件分析
with open('rhyme_nodes.csv', 'w', encoding='utf-8-sig') as f:
    f.write('Id,Label\n')
    for id,_ in enumerate(nodes_data):
        f.write(str(id) + ',' + _ + '\n')

# 没事就排个序，以便我等凡夫肉眼观看
graph_sort = sorted(graph.items(), key=lambda x:x[1], reverse=True)
with open('rhyme_graph.csv', 'w', encoding='utf-8-sig') as f:
    f.write('Id,Source,Target,Type,Weight\n')
    i=0
    for _key, _value in graph_sort:
        f.write(str(i) + ',' + str(nodes_data.index(_key[0])) + ',' 
                + str(nodes_data.index(_key[-1])) + ',' 
                + 'undirected' + ',' + str(3000/_value) + '\n' )
        i += 1
```

OK，利用这里生成的两个 CSV 文件（一个顶点文件，一个边的文件），导入到 Gephi 软件（神器啊！！真的是神器！！）中分析，得出下图：

![1574348745951](D:\myfiles\poem\picture\graph.png)

​	激动啊！激动人心的场面出现了！！为了看起来方便，我稍微调整了字的位置。从图中可以看出，我们的数学模型还是比较成功的。基本上将高频的 2000 多个字按韵母进行了分类。

​	尤其是请注意右上角的“**恶**“字和左上角的”**行**“字，它们的多音字的特性也很好的显现了出来。

​	请注意，在整个数据的处理过程中，我们是对这几千个字的读音一无所知的（知也假装不知）。但是我们”暴力“的利用十万首诗中它们所出现的位置，以及位置与字音相关的”**信息**“就得出了它们押韵的基本规律。

​	这，就是通常所说的大数据分析。

​	话说回来。根据我们先前想象的，求**极大连通子图（又称连通分量）**来获取各个押韵的组，显然有些行不通了。因为多音字和不押韵的字的错用，导致这个图在不同韵的字之间，并没有很绝对的不连通。怎么办？

------

（枯燥的理论分割线）

​	这里如果要深入学习，就进入了图论中**社区发现算法**的广阔天地。学习曲线开始陡增。感兴趣的可以搜索” Newman 社区发现算法“。原始论文可以参看下面的 PDF 文档。

[Modularity and community structure in networks](https://www.pnas.org/content/pnas/103/23/8577.full.pdf)

​	综合性的介绍可以看这篇文章：

 [社区发现(Community Detection)算法](https://blog.csdn.net/cleverlzc/article/details/39494957)

------

​	不过各位别怕，咱们是新手，新手就有新手的玩法。因为我们这里，有个简易的算法。

​	其实，我们的图的每一条边的权，记录了两个字押韵的可能性。只要我们将距离较远（押韵可能性低）的”视为“不连通就可以啦！那多远才能叫不押韵呢？我也不知道。只能不停的调啊调一个参数。难道这就是传说中人工智能大活中的苦力活——”调参“？

​	顺便说下，求极大连通子图，是通过不连通性的深度搜索实现的。代码如下：

```python
# 打开上面生成的两个 csv 文件
with open('rhyme_nodes.csv', 'r', encoding='utf-8-sig') as f:
    word_list = f.read().split('\n')
    word_list = word_list[1:]
    word_list = word_list[:-1]

with open('rhyme_graph.csv', 'r', encoding='utf-8-sig') as f:
    rhyme_list = f.read().split('\n')
    rhyme_list = rhyme_list[1:]

# 去除用于 Gephi 软件的不必要的信息
for index, _ in enumerate(rhyme_list):
    _ = _.split(',')
    rhyme_list[index] = _[1:3] + _[-1:]

# 一个字典标记一个节点是否已被分析
in_community = {}
for _ in range(len(word_list)):
    in_community[_] = 0

# 整合模块（组）的子程序
def modularise(node, sub_com, g, judge_dict):
    sub_com.append(node)
    # 标记已纳入某个韵组
    judge_dict[node] = 1
    for _ in g:
        if str(node) in _:
            if str(node) == _[0]:
                next_node = _[1]
            else:
                next_node = _[0]
            # 此处的 200 就是前面提到的参数，越大，分类越模糊，越小越细
            if in_community[int(next_node)]==0 and float(_[2]) < 200:
                # 递归实现深度搜索
                modularise(int(next_node), sub_com, g, judge_dict)

modularity_list = []
# 对所有节点，整合到某个韵组中
for node in range(len(word_list)):
    sub_community = []
    if in_community[node] == 0:
        modularise(node, sub_community, rhyme_list, in_community)
        modularity_list.append(sub_community)
            
# 输出
for _, sub_mod in enumerate(modularity_list):
    print(_)
    for word_num in sub_mod:
        print(word_list[word_num][-1], end=' ')
    print('')
```

​	让我们看看输出的结果：

```
0 恶 落 薄 乐 作 壑 阁 廓 託 药 鹤 着 索 酌 错
1 桑 长 香 凉 光 阳 乡 霜 黄 芳 堂 忘 方 伤 肠 觞 行 生 声 情 清 明 城 名 成 平 轻 荣 卿 兵 营 耕 鸣 惊 横 兄 争 迎 倾  龄 庭 青 亭 星 经 灵 冥 形 听 醒 萍 零 腥 境 影 永 冷 省 井 岭 景 静 性 病 命 定 领 屏 扃 铭 停 馨 宁 刑 溟 更 盈 京 程 旌 晴 盟 征 缨 精 英 嵘 楹 衡 并 诚 评 荆 瀛 烹 羹 郎 章 场 王 扬 茫 房 墙 苍 藏 荒 傍 翔 常 庄 忙 狂 亡 强 牀 裳 望 上 赏 响 想 往 壮 浪 量 梁 当 皇 良 昌 唐 祥 尝 汤 床 囊 央 妨 旁 塘 冈 装 康 湘 张 廊 羊 浆 杨 将 航 芒 昂
2 速 曲 绿 足 目 玉 谷 竹 屋 木 独 宿 逐 卜 復 熟 覆 腹 肉 僕 烛 续 俗 辱 麓 粟 束 禄 读 促 欲 躅 菊 触 哭 福
3 云 分 闻 君 文 羣 纷 曛 氛 军 勋 薰 焚 氲 勤 人 春 新 尘 身 真 亲 邻 频 神 津 秦 臣 辰 陈 因 宾 贫 巾 民 钧 仁 伸 滨  鳞 驯 轮 绅 珍 匀 薪 辛 晨 麟 纶 伦 旬 均 巡 淳 醇 沦 嗔 宸 苹 欣 坟 芬 门 村 昏 魂 论 存 尊 孙 言 园 繁 翻 原 喧 源 根 痕 恩 垣 温 奔 坤 吞 轩 烦 樽 元 浑 偏 年 天 然 烟 前 泉 眠 船 边 贤 传 仙 缘 禅 圆 全 先 田 川 悬 旋 鲜 妍 篇 玄 编 迁 连 弦 肩 怜 颠 钱 千 联 捐 宣 莲 筵 鞭 渊 延 还 山 间 闲 关 颜 攀 斑 顽 艰 悭 环 班 难 寒 看 安 宽 官 欢 干 端 盘 丹 冠 残 乾 坛 阑 酸 鞍 兰 竿 澜 观 弹 餐 栏 翰 漫 滩 湍 肝 鸾 嘆 叹 半 散 乱 断 汉 岸 旦 湾 寰 煎 蝉 阡 坚 权 穿 牵 巅 湲 绵 娟 便 面 见 变 转 絃 翩 焉 屯 藩 盆 辕
4 违 归 衣 飞 微 稀 扉 机 非 依 辉 威 肥 霏 围 晖 矶 时 迟 诗 知 期 枝 池 移 悲 丝 衰 思 姿 师 持 之 辞 离 垂 宜 为 奇  窥 随 危 追 驰 儿 仪 规 吹 碑 谁 卑 饥 兹 疑 私 施 夷 芝 欺 遗 旗 资 眉 词 墀 祠 滋 痴 巵 披 差 花 家 华 斜 车 书 馀 居 疎 如 虚 初 鱼 疏 庐 舒 裾 除 渠 蔬 锄 徐 途 无 湖 孤 图 夫 虞 愚 儒 区 符 隅 俱 娱 鬚 珠 殊 躯 趋 涂 呼 扶 枯 苏 芜 都 徒 吴 衢 壶 须 乌 蒲 驱 吁 舆 墟 予 闾 渔 欤 躇 霞 沙 涯 赊 鸦 嗟 夸 嘉 牙 茶 芽 麻 譁 加 蛇 槎 怀 斋 谐 泥 西 迷 低 齐 啼 溪 题 携 栖 畦 梯 蹊 鸡 蹄 回 来 开 台 才 哀 哉 埃 迴 催 梅 杯 苔 徊 摧 灰 雷 堆 材 莱 媒 栽 猜 嵬 裁 陪 隈 瓜 遮 佳 篱 帷 羁 陂 湄 嬉 颐 斯 疲 龟 基 岐 医 慈 漪 薇 挥 几 水 里 起 耳 子 死 此 尔 理 美 止 喜 已 始 耻 齿 矣 士 己 似 字 事 意 气 地 至 醉 睡 味 翠 致 异 泪 义 志 贵 岁 计 史 纸 指 底 倚 市 洗 比 闱
5 吟 心 深 林 阴 寻 音 琴 襟 侵 沉 金 簪 今 岑 临 禽 斟 任 森 霖 禁 砧 参 南 甘 谈
6 愁 秋 流 游 留 舟 头 楼 州 忧 求 休 丘 浮 幽 收 谋 修 酬 不 俦 投 侯 优 羞 牛 由 畴 周 柔 裘 稠 悠 洲 鸥 钩 筹 尤 讴  囚 遒 猷 沟
7 和 多 何 歌 波 过 河 罗 戈 萝 磨 科 阿 卧 破 坐 大 外 会 背 对 爱 在 待 盖 跎 荷 柯 娑
8 风 中 空 同 翁 红 通 功 穷 公 雄 东 鸿 工 宫 容 峰 松 重 逢 龙 从 踪 钟 浓 锺 封 舂 宗 胸 用 动 梦 共 冬 供 融 丛 蓬  终 童 崇 戎 弓 忠 隆 蒙 丰 桐 虫 笼 虹 濛 攻
9 举 雨 语 许 苦 古 取 土 主 数 故 路 去 处 住 树 暮 素 度 步 趣 句 露 具 顾 遇 雾 虑 户 补 吐 府 舞 鼓 宇 午 羽 虎 与  暑 所 楚 女 渚
10 集 立 入 急 湿 及
11 益 迹 石 碧 色 极 力 食 息 翼 识 德 国 得 北 侧 隔 客 白 夕 役 适 席 壁 滴 寂 实 出 日 疾 失 质 密 术 室 毕 一 笔 逸 瑟 骨 没 月 发 歇 越 阙 绝 雪 折 别 灭 结 热 节 洁 说 髮 辙 阔 物 策 陌 宅 尺 昔 窄 易 迫 璧 籍 直 黑 历 积 泽 惜
12 蹰
13 豪 高 劳 骚 毛 袍 曹 蒿 刀 遭 涛 号 毫 逃 皋 陶 朝 遥 桥 招 寥 霄 腰 潮 消 摇 条 凋 饶 飘 萧 樵 销 骄
14 县
15 下 马 者 野 舍 夜
16 冰 僧 灯 能 兴 陵 登 层 凝 腾 升 称 乘 胜
17 偶
18 倒 草 道 老 好 早 抱 藁 扫 宝 表 小 了 晓 鸟 少 照 笑 调
19 有 首 酒 柳 丑 口 走 斗 手 久 朽 后 友 守 厚 牖 否
20 远 晚 浅
21 推
22 是
23 弃
24 怡
25 维
26 画
27 商
28 径
29 嗤
30 怒
31 臆
32 世
33 累
34 污
35 疆
36 支
37 正 盛
38 敌
39 利
40 亏
41 燕
42 聚
```

​	呃…… 第一次看到，还真有的小激动呢。竟然成功的分出来了！虽然，还是很不完美。

​	不过等等，我们还可以对那些字数很多的组，例如上面的组1，组3和组4再分一次。

```python
# 对于字数太多的组，我们可以用更严格的要求再分组一次
for _ in modularity_list:
    # 大于120个字的组
    if len(_)>120:
        sub_modularity = []
        in_community = {}
        sub_rhyme_list = []
        for _node in _:
            in_community[_node] = 0
        # 提取一个社区的所有的边
        for _edge in rhyme_list:
            if _edge[0] and int(_edge[0]) in _ and int(_edge[1]) in _:
                sub_rhyme_list.append(_edge)
        # 运算
        for node in _:
            sub_community = []
            if in_community[int(node)] == 0:
                modularise(int(node), sub_community, sub_rhyme_list, in_community, 120)
                sub_modularity.append(sub_community)
        # 输出
        for _, sub_mod in enumerate(sub_modularity):
            print(_)
            for word_num in sub_mod:
                print(word_list[word_num][-1], end=' ')
            print('\n')
```

​	对其中的组1、组3和组4，再分一次的结果是这样的：

​	组1

```
0 桑 长 香 凉 光 阳 乡 霜 黄 芳 堂 忘 方 伤 肠 觞 王 亡 傍 藏 章 场 苍 郎 行 生 声 情 清 明 城 名 成 平 轻 荣 卿 倾 惊  鸣 晴 横 兄 迎 耕 营 兵 征 程 京 英 旌 缨 精 盈 评 衡 更 并 荆 楹 诚 盟 争 嵘 羹 烹 狂 茫 良 房 翔 常 荒 尝 忙 湘 裳 浪 上 赏 响 想 往 望 壮 梁 塘 祥 墙 皇 央 扬 康 床 牀 廊 装 囊 量 将 冈 强 张 杨 旁 汤
1 龄 庭 青 亭 星 经 灵 冥 形 听 醒 萍 扃 屏 腥 刑 停 零 铭
2 境 影 永 冷 景 岭 静 井 省
3 性
4 病
5 命
6 定
7 领
8 馨
9 宁
10 溟
11 瀛
12 庄
13 当
14 昌
15 唐
16 妨
17 羊
18 浆
19 航
20 芒
21 昂
```

​	组3

```
0 云 分 闻 君 文 羣 纷 氛 军 勋 薰 勤 人 春 新 尘 身 真 亲 邻 频 神 津 秦 鳞 滨 民 臣 辰 陈 绅 巾 贫 宾 珍 因 均 伦 晨  仁 辛 轮 嗔 纶 伸 巡 旬 匀 宸 苹 麟 薪 驯 沦 钧 醇 坟 曛 芬 焚 氲 欣
1 淳
2 门 村 昏 魂 论 存 尊 孙 言 园 繁 翻 原 喧 源 根 痕 恩 垣 温 轩 吞 偏 年 天 然 烟 前 泉 眠 船 边 贤 传 仙 缘 禅 篇 田  川 悬 旋 鲜 妍 连 钱 渊 圆 全 先 筵 千 怜 弦 迁 宣 肩 颠 阡 蝉 牵 莲 编 絃 坚 翩 煎 巅 鞭 延 绵 玄 山 间 闲 还 关 颜 攀 斑 顽 悭 环 艰 班 湾 寰 难 寒 看 安 宽 官 欢 干 冠 端 盘 观 残 乾 坛 弹 阑 澜 丹 酸 竿 鞍 栏 餐 滩 鸾 兰 湍 肝 叹 樽 元 坤 奔 浑 屯 盆
3 烦
4 联
5 捐
6 翰
7 漫
8 嘆
9 半
10 散
11 乱 断
12 汉 岸
13 旦
14 权
15 穿
16 湲
17 娟
18 便
19 面 见 变
20 转
21 焉
22 藩
23 辕
```

​	组4

```
0 违 归 衣 飞 微 稀 扉 机 非 依 辉 晖 围 肥 威 薇 挥 霏 闱 矶 悲 时 迟 诗 知 期 枝 池 移 垂 宜 之 辞 离 思 姿 师 持 疑  兹 为 奇 窥 随 儿 饥 衰 丝 眉 欺 驰 吹 滋 篱 巵 词 谁 碑 危 卑 遗 夷 规 私 颐 斯 祠 旗 墀 披 仪 帷 基 痴 陂 岐 差 花 家 华 斜 车 书 馀 居 疎 如 虚 初 鱼 疏 庐 舒 渠 除 裾 蔬 锄 闾 无 湖 孤 图 夫 呼 隅 俱 壶 枯 途 珠 殊 都 娱 鬚 须 扶 墟 舆 渔 驱 徐 予 儒 躇 霞 沙 涯 赊 鸦 嗟 嘉 槎 夸 欤 茶 芽 蛇 遮 瓜 加 麻 牙 譁 佳 医 施 追
1 芝
2 资
3 虞
4 愚
5 区
6 符
7 躯
8 趋
9 涂
10 苏
11 芜
12 徒
13 吴
14 衢
15 乌
16 蒲
17 吁
18 怀 斋 开 来 台 回 梅 杯 催 迴 埃 才 哀 哉 猜 苔 灰 徊 摧 雷 隈 莱 材 栽 嵬 裁 媒 陪 堆 谐
19 泥 西 迷 低 齐 啼 溪 题 携 栖 鸡 梯 蹄
20 畦
21 蹊
22 羁
23 湄
24 嬉
25 疲
26 龟
27 慈
28 漪
29 几 水 里 起 耳 子 死 此 喜 已 止 理 美 尔 士 似 史 纸 底 齿 耻 始 洗 矣
30 己
31 字
32 事 意 气 地 至 醉 睡 翠 泪 味
33 致
34 异
35 义
36 志
37 贵
38 岁
39 计
40 指
41 倚
42 市
43 比
```

​	不错，不错，虽然还是不完美，不过对于我们采取的这个暴力、简单的方法来说，也已经很不错啦。让我们最后用一些可耻（捂脸）的微（手）小（动）的调整。最终韵律分组如下：

```
0 恶 落 薄 乐 作 壑 阁 廓 託 药 鹤 着 索 酌 错
1 桑 长 香 凉 光 阳 乡 霜 黄 芳 堂 忘 方 伤 肠 觞 王 亡 傍 藏 章 场 苍 郎 行 狂 茫 良 房 翔 常 荒 尝 忙 湘 裳 浪 上 赏 响 想 往 望 壮 梁 塘 祥 墙 皇 央 扬 康 床 牀 廊 装 囊 量 将 冈 强 张 杨 旁 汤 庄 当 昌 唐 妨 羊 浆 航 芒 昂 商 疆
2 生 声 情 清 明 城 名 成 平 荣 卿 倾 惊 鸣 晴 横 兄 迎 耕 征 程 旌 缨 评 衡 更 并 诚 盟 争 嵘 羹 烹 冷 
3 龄 庭 青 亭 星 经 灵 冥 形 听 醒 萍 扃 屏 腥 刑 停 零 铭 荆 楹 景 岭 静 井 省 营 兵 京 英 精 盈 轻 馨 宁 溟 瀛
4 速 曲 绿 足 目 玉 谷 竹 屋 木 独 宿 逐 卜 復 熟 覆 腹 肉 僕 烛 续 俗 辱 麓 粟 束 禄 读 促 欲 躅 菊 触 哭 福
5 人 尘 门 村 昏 魂 论 存 尊 孙 分 闻 文 羣 纷 氛 勤 新 身 真 亲 邻 频 神 津 秦 鳞 滨 民 臣 辰 陈 绅 巾 贫 宾 珍 因 伦 晨 仁 辛 轮 嗔 纶 伸 宸 苹 麟 薪 驯 沦 钧 醇 坟 曛 芬 焚 欣
6 云 君 淳 军 勋 薰 春 巡 旬 匀 氲 均 坤 奔 浑 屯 盆 樽
7 言 园 繁 翻 原 喧 源 根 痕 恩 垣 温 轩 吞 偏 年 天 然 烟 前 泉 眠 船 边 贤 传 仙 缘 禅 篇 田 川 悬 旋 鲜 妍 连 钱 渊 圆 全 先 筵 千 怜 弦 迁 宣 肩 颠 阡 蝉 牵 莲 编 絃 坚 翩 煎 巅 鞭 延 绵 玄 山 间 闲 还 关 颜 攀 斑 顽 悭 环 艰 班 湾 寰 权 穿 湲 娟 焉 藩 辕
8 难 寒 看 安 宽 官 欢 干 冠 端 盘 观 残 乾 坛 弹 阑 澜 丹 酸 竿 鞍 栏 餐 滩 鸾 兰 湍 肝 叹 元 烦 联 捐 翰 汉 岸
9 漫 嘆 半 散 乱 断 旦
10 便 面 见 变 转
11 违 归 飞 微 稀 扉 非 依 医 施 追 辉 晖 围 肥 威 薇 挥 霏 闱 悲 为 窥 随 吹 谁 碑 危 卑 规 帷 陂  眉 湄 畦 龟 维 亏
12 时 迟 诗 知 枝 池 移 垂 之 师 持 驰 痴 岐 芝 支 石 食 识 适 湿 实 日 失
13 遗 夷 私 颐 斯 祠 旗 墀 披 仪 基 矶 期 宜 辞 离 思 姿 疑 兹 奇 机 饥 丝 欺 滋 篱 巵 词 资 羁 蹊 嬉 疲 慈 漪 泥 西 迷 低 齐 啼 溪 题 携 栖 鸡 梯 蹄 敌 益 迹 碧 极 力 息 翼 夕 役 席 壁 滴 寂 急 及 集 立 疾 一 笔 逸 昔 籍 惜 衣 历 积 直
14 馀 居 疎 如 虚 初 鱼 疏 庐 舒 渠 除 裾 蔬 锄 闾 无 湖 孤 图 夫 呼 隅 俱 壶 枯 途 珠 殊 都 娱 鬚 须 扶 墟 舆 渔 驱 徐 予 儒 躇 欤 书 虞 愚 区 符 躯 趋 涂 苏 芜 徒 吴 衢 乌 蒲 吁 污 蹰 出
15 茶 芽 蛇 遮 瓜 加 麻 牙 譁 佳 沙 涯 嘉 槎 夸 差 花 家 华 斜 霞 赊 鸦 嗟 发 髮
16 儿 衰 怀 斋 开 来 台 回 梅 杯 催 迴 埃 才 哀 哉 猜 苔 灰 徊 摧 雷 隈 莱 材 栽 嵬 裁 媒 陪 堆 谐  白
17 吟 心 深 林 阴 寻 音 琴 襟 侵 沉 金 簪 今 岑 临 禽 斟 任 森 霖 禁 砧 参 南 甘 谈
18 愁 秋 流 游 留 舟 头 楼 州 忧 求 休 丘 浮 幽 收 谋 修 酬 不 俦 投 侯 优 羞 牛 由 畴 周 柔 裘 稠 悠 洲 鸥 钩 筹 尤 讴  囚 遒 猷 沟
19 和 多 何 歌 波 过 河 罗 戈 萝 磨 科 阿 卧 破 坐 大 外 会 背 对 爱 在 待 盖 跎 荷 柯 娑 国 阔
20 风 中 空 同 翁 红 通 功 穷 公 雄 东 鸿 工 宫 容 峰 松 重 逢 龙 从 踪 钟 浓 锺 封 舂 宗 胸 用 动 梦 共 冬 供 融 丛 蓬  终 童 崇 戎 弓 忠 隆 蒙 丰 桐 虫 笼 虹 濛 攻
21 举 雨 语 许 苦 古 取 土 主 数 故 路 去 处 住 树 暮 素 度 步 趣 句 露 具 顾 遇 雾 虑 户 补 吐 府 舞 鼓 宇 午 羽 虎 与 暑 所 楚 女 渚
22 色 德 得 瑟 辙 宅 窄 黑 泽 车
23 歇 越 阙 绝 雪 折 别 灭 结 热 节 洁 说 
24 北 侧 隔 客 
25 豪 高 劳 骚 毛 袍 曹 蒿 刀 遭 涛 号 毫 逃 皋 陶 朝 遥 桥 招 寥 霄 腰 潮 消 摇 条 凋 饶 飘 萧 樵 销 骄
26 冰 僧 灯 能 兴 陵 登 层 凝 腾 升 称 乘 胜
27 倒 草 道 老 好 早 抱 藁 扫 宝 表 小 了 晓 鸟 少 照 笑 调
28 有 首 酒 柳 丑 口 走 斗 手 久 朽 后 友 守 厚 牖 否
29 远 晚 浅
```

​	终于，终于，又可以开始写诗了，让我们把上面自己总结出来的韵律分组存为 csv 文件，然后开干！

```python
import sys
import json
import random

with open('pos_top500.json', 'r', encoding='utf-8-sig') as f:
    pos_500_data = json.loads(f.read())

with open('double_word_dict_head.json', 'r', encoding='utf-8-sig') as f:
    double_word_data = json.loads(f.read())

with open('double_word_dict_end.json', 'r', encoding='utf-8-sig') as f:
    double_word_end_data = json.loads(f.read())

rhyme_list = []
with open('rhyme.csv', 'r', encoding='utf-8-sig') as f:
    line = f.readline()
    while line:
        rhyme = [_ for _ in line.split(',')[1:] if _ and _!='\n']
        rhyme_list.append(rhyme)
        line = f.readline()

def make_poem(pos_data, double_data, double_end_data, rhyme=['流', '楼']):
    
    def get_double_word(word, end=False):
        # 自后字取词，用于配押韵字的词
        if end:
            _list = double_end_data[word][:int(len(double_end_data) / 3) + 1]
        else:
            _list = double_data[word][:int(len(double_data) / 3) + 1]
        random.shuffle(_list)
        return _list[0]

    
    def make_sentence(no, _type, rhyme=rhyme):
        '''
        no: the sentence number
        type 0:$$@$$
        type 1:$$$$@
        '''
        sentence = ''
        word_1 = pos_data[str((no - 1) * 5)][random.randrange(0,300)][0]
        sentence += get_double_word(word_1)
        word_3 = pos_data[str((no - 1) * 5 + 2)][random.randrange(0,300)][0]
        if _type:
            sentence += get_double_word(word_3)
            if no == 1 or no == 3:
                sentence += pos_data[str((no - 1) * 5 + 4)][random.randrange(0,300)][0]
            else:
                # 末字押韵
                sentence += rhyme[int(no / 2) - 1]
        else:
            sentence += word_3
            if no == 2 or no == 4:
                # 末字押韵，然后向前配词
                word_4 = rhyme[int(no /2) - 1]
                sentence += get_double_word(word_4, end=True)
            else:
                word_4 = pos_data[str((no - 1) * 5 + 3)][random.randrange(0,300)][0]
                sentence += get_double_word(word_4)

        return sentence
    
    _poem = []

    sentence1_type = random.randrange(0, 2)
    sentence3_type = random.randrange(0, 2)
    _poem.append(make_sentence(1, sentence1_type))
    _poem.append(make_sentence(2, sentence1_type, rhyme_word))
    _poem.append(make_sentence(3, sentence3_type))
    _poem.append(make_sentence(4, sentence3_type, rhyme_word))

    return _poem


#rhyme_word = ['烟', '关']
# 输出
for _ in range(5):
    # 取韵字
    random.shuffle(rhyme_list)
    random.shuffle(rhyme_list[0])
    rhyme_word = rhyme_list[0][:2]
    poem = make_poem(pos_500_data, double_word_data, double_word_end_data, rhyme_word)
    for __ in poem:
        print(__)
    print('')
```



​	激动人心的时刻到了，开工！欣赏下结果：

```
月澄仍后功
终居破莲栽
绿樽水在鹤
独往花谢埃

官职旧田薄
聊观过仍苦
若休九川岭
暮戏花世路

主何復东窗
胡窥杂登嵬
北道堪藏人
非重足堪白

彼柳交之比
乃登老大手
共对人车成
诗磨仍竹走

红腰随轻渐
溪遶绿崭绝
石惊得尚忧
心亡奉况别
```

​	最后一首

	红腰随轻渐
	溪遶绿崭绝
	石惊得尚忧
	心亡奉况别
​	啧啧，还很有那么点意思了呢！而且关键是：

​	完美押韵！那么我们就剩最后一个小课题，平仄对仗啦！



<待续>